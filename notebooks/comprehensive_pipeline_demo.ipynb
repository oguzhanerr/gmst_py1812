{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "main_title",
   "metadata": {},
   "source": [
    "# GMST-Py1812: Complete Pipeline Demonstration\n",
    "\n",
    "This notebook demonstrates all 5 phases of the ITU-R P.1812-6 radio propagation prediction pipeline.\n",
    "\n",
    "## Phases Overview\n",
    "- **Phase 0**: Setup - Initialize environment, load and validate configuration\n",
    "- **Phase 1**: Data Preparation - Download and cache land cover data from Sentinel Hub\n",
    "- **Phase 2**: Batch Point Generation - Create receiver grid using point_generation utilities\n",
    "- **Phase 3**: Batch Data Extraction - Extract elevation and land cover at receiver points\n",
    "- **Phase 4**: Formatting & Export - Format profiles and validate CSV output\n",
    "- **Phase 5**: P.1812 Analysis - Calculate propagation loss and field strength\n",
    "\n",
    "Each phase demonstrates key functions and modules from the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_phase0",
   "metadata": {},
   "source": [
    "# Phase 0: Setup & Configuration\n",
    "\n",
    "Initialize environment and load validated configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase0_imports",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import ast\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterable, Union, List, Tuple, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import Py1812.P1812\n",
    "\n",
    "print(\"\u2713 All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase0_paths",
   "metadata": {},
   "source": [
    "## Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and add project root to path\n",
    "possible_roots = [\n",
    "    Path.cwd(),\n",
    "    Path.cwd().parent,\n",
    "    Path.cwd().parent.parent,\n",
    "]\n",
    "\n",
    "project_root = None\n",
    "for root in possible_roots:\n",
    "    if (root / 'src' / 'pipeline').exists() or (root / 'config_example.json').exists():\n",
    "        project_root = root\n",
    "        break\n",
    "\n",
    "if project_root and str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "# Try to import Sentinel Hub credentials\n",
    "try:\n",
    "    from config_sentinel_hub import (\n",
    "        SH_CLIENT_ID, SH_CLIENT_SECRET,\n",
    "        TOKEN_URL, PROCESS_URL, COLLECTION_ID,\n",
    "    )\n",
    "except ImportError:\n",
    "    SH_CLIENT_ID = ''\n",
    "    SH_CLIENT_SECRET = ''\n",
    "    TOKEN_URL = ''\n",
    "    PROCESS_URL = ''\n",
    "    COLLECTION_ID = ''\n",
    "\n",
    "# Define all data paths\n",
    "profiles_dir = project_root / 'data' / 'profiles'\n",
    "landcover_dir = project_root / 'data' / 'landcover'\n",
    "output_dir = project_root / 'data' / 'output'\n",
    "srtm_dir = project_root / 'data' / 'srtm'\n",
    "brzones_dir = project_root / 'data' / 'brzones'\n",
    "\n",
    "# Create directories\n",
    "for d in [profiles_dir, landcover_dir, output_dir, srtm_dir, brzones_dir]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print('\u2713 All data directories created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase0_config",
   "metadata": {},
   "source": [
    "## Configuration Management\n",
    "\n",
    "Load, validate, and extract configuration using ConfigManager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import configuration management utilities\n",
    "from pipeline.config import (\n",
    "    ConfigManager,\n",
    "    _load_sentinel_hub_credentials,\n",
    "    get_transmitter_info,\n",
    "    get_p1812_params,\n",
    "    get_receiver_generation_params,\n",
    "    get_land_cover_mappings,\n",
    ")\n",
    "\n",
    "# Load and validate configuration\n",
    "config_path = project_root / 'config_example.json'\n",
    "if not config_path.exists():\n",
    "    raise FileNotFoundError(f'Config file not found: {config_path}')\n",
    "\n",
    "config_mgr = ConfigManager.from_file(config_path)\n",
    "CONFIG = config_mgr.config\n",
    "\n",
    "# IMPORTANT: Load Sentinel Hub credentials from config_sentinel_hub.py\n",
    "CONFIG = _load_sentinel_hub_credentials(CONFIG)\n",
    "\n",
    "print(f'\u2713 Loaded and validated configuration from {config_path.name}')\n",
    "print(f'\u2713 Sentinel Hub credentials loaded from config_sentinel_hub.py')\n",
    "\n",
    "# Extract configuration sections\n",
    "tx_info = get_transmitter_info(CONFIG)\n",
    "p1812_params = get_p1812_params(CONFIG)\n",
    "rx_gen_params = get_receiver_generation_params(CONFIG)\n",
    "\n",
    "print(f'\\nTransmitter:')\n",
    "for key, val in tx_info.items():\n",
    "    print(f'  {key}: {val}')\n",
    "\n",
    "print(f'\\nP.1812 Parameters:')\n",
    "for key, val in p1812_params.items():\n",
    "    print(f'  {key}: {val}')\n",
    "\n",
    "print(f'\\nReceiver Generation:')\n",
    "print(f'  Max distance: {rx_gen_params[\"max_distance_km\"]} km')\n",
    "print(f'  Azimuth step: {rx_gen_params[\"azimuth_step\"]}\u00b0')\n",
    "print(f'  Distance step: {rx_gen_params[\"distance_step\"]} km')\n",
    "\n",
    "# Derived values\n",
    "tx_lon = tx_info['longitude']\n",
    "tx_lat = tx_info['latitude']\n",
    "max_distance_km = rx_gen_params['max_distance_km']\n",
    "azimuths = list(range(0, 360, rx_gen_params['azimuth_step']))\n",
    "distances = np.arange(\n",
    "    rx_gen_params['distance_step'],\n",
    "    max_distance_km + rx_gen_params['distance_step'],\n",
    "    rx_gen_params['distance_step']\n",
    ")\n",
    "\n",
    "print(f'\\nDerived:')\n",
    "print(f'  Azimuths: {len(azimuths)} steps')\n",
    "print(f'  Distances: {len(distances)} steps')\n",
    "print(f'  Total receiver points: {len(azimuths) * len(distances)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase0_transmitter",
   "metadata": {},
   "source": [
    "## Transmitter Definition\n",
    "\n",
    "Create transmitter using actual pipeline Transmitter class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transmitter_class",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.point_generation import Transmitter\n",
    "\n",
    "tx = Transmitter(\n",
    "    tx_id=tx_info['tx_id'],\n",
    "    lon=tx_info['longitude'],\n",
    "    lat=tx_info['latitude'],\n",
    "    htg=tx_info['antenna_height_tx'],\n",
    "    hrg=tx_info['antenna_height_rx'],\n",
    "    f=p1812_params['frequency_ghz'],\n",
    "    pol=p1812_params['polarization'],\n",
    "    p=p1812_params['time_percentage'],\n",
    ")\n",
    "\n",
    "print(f\"\u2713 Transmitter created:\")\n",
    "print(f\"  {tx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase0_elevation",
   "metadata": {},
   "source": [
    "## Elevation Data Initialization\n",
    "\n",
    "Initialize and cache SRTM elevation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elevation_seed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from propagation.profile_extraction import set_srtm_cache_dir, _get_srtm_data\n",
    "\n",
    "print(\"\\nInitializing SRTM elevation data...\")\n",
    "init_start = time.time()\n",
    "\n",
    "try:\n",
    "    # Set SRTM cache directory\n",
    "    set_srtm_cache_dir(str(srtm_dir))\n",
    "    \n",
    "    # Initialize SRTM data handler\n",
    "    srtm_data = _get_srtm_data()\n",
    "    \n",
    "    # Pre-download tile\n",
    "    print(f\"  Downloading SRTM1 tile for TX area ({tx_lat}, {tx_lon})...\")\n",
    "    tx_elev = srtm_data.get_elevation(tx_lat, tx_lon)\n",
    "    \n",
    "    init_time = time.time() - init_start\n",
    "    print(f\"\u2713 SRTM elevation data ready ({init_time:.2f}s)\")\n",
    "    print(f\"  TX elevation: {tx_elev}m\")\n",
    "    \n",
    "    # Load HGT tile into memory\n",
    "    hgt_files = glob.glob(str(srtm_dir / \"*.hgt\"))\n",
    "    if hgt_files:\n",
    "        hgt_path = hgt_files[0]\n",
    "        print(f\"\\n  Loading HGT tile into memory...\")\n",
    "        with rasterio.open(hgt_path) as dem_src:\n",
    "            dem_band_data = dem_src.read(1)\n",
    "            dem_transform = dem_src.transform\n",
    "        print(f\"  \u2713 HGT loaded: {dem_band_data.shape} array\")\n",
    "    else:\n",
    "        dem_band_data = None\n",
    "        dem_transform = None\n",
    "        \nexcept Exception as e:\n",
    "    print(f\"\u2717 Error initializing SRTM: {e}\")\n",
    "    srtm_data = None\n",
    "    dem_band_data = None\n",
    "    dem_transform = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_phase1",
   "metadata": {},
   "source": [
    "# Phase 1: Data Preparation\n",
    "\n",
    "Land cover download using Sentinel Hub utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phase1_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.data_preparation import prepare_landcover\n",
    "from propagation.profile_extraction import resolve_credentials\n",
    "\n",
    "print(\"\\nPhase 1: Data Preparation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get Sentinel Hub config from CONFIG (now with credentials loaded)\n",
    "sh_config = CONFIG.get('SENTINEL_HUB', {})\n",
    "client_id = sh_config.get('client_id', '').strip()\n",
    "client_secret = sh_config.get('client_secret', '').strip()\n",
    "collection_id = sh_config.get('collection_id', '').strip()\n",
    "token_url = sh_config.get('token_url', '')\n",
    "process_url = sh_config.get('process_url', '')\n",
    "\n",
    "print(f\"\\nSentinel Hub Configuration:\")\n",
    "print(f\"  Has client_id: {bool(client_id)}\")\n",
    "print(f\"  Has client_secret: {bool(client_secret)}\")\n",
    "print(f\"  Has collection_id: {bool(collection_id)}\")\n",
    "\n",
    "if client_id and client_secret and collection_id:\n",
    "    print(f\"\\nAttempting land cover download...\")\n",
    "    print(f\"  Location: ({tx_lat}, {tx_lon})\")\n",
    "    print(f\"  Collection ID: {collection_id[:8]}... (truncated)\")\n",
    "    print(f\"  Save to: {landcover_dir}\")\n",
    "    \n",
    "    try:\n",
    "        start = time.time()\n",
    "        lc_path = prepare_landcover(\n",
    "            lat=tx_lat,\n",
    "            lon=tx_lon,\n",
    "            cache_dir=landcover_dir,\n",
    "            client_id=client_id,\n",
    "            client_secret=client_secret,\n",
    "            token_url=token_url,\n",
    "            process_url=process_url,\n",
    "            collection_id=collection_id,\n",
    "            year=sh_config.get('year', 2020),\n",
    "            buffer_m=sh_config.get('buffer_m', 11000),\n",
    "            chip_px=sh_config.get('chip_px', 734),\n",
    "            verbose=True,\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"\\n\u2713 Land cover preparation complete ({elapsed:.1f}s)\")\n",
    "        print(f\"  Saved to: {lc_path.name}\")\n",
    "        print(f\"  File size: {lc_path.stat().st_size / (1024*1024):.1f} MB\")\n",
    "        phase1_landcover_path = lc_path\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)[:200]\n",
    "        print(f\"\\n\u2717 Download failed: {error_msg}\")\n",
    "        phase1_landcover_path = None\n",
    "else:\n",
    "    print(f\"\\n\u2717 Missing Sentinel Hub configuration\")\n",
    "    if not client_id:\n",
    "        print(f\"  - client_id is empty\")\n",
    "    if not client_secret:\n",
    "        print(f\"  - client_secret is empty\")\n",
    "    if not collection_id:\n",
    "        print(f\"  - collection_id is empty\")\n",
    "    phase1_landcover_path = None\n",
    "\n",
    "print(f\"\\nPhase 1 Status: {'\u2713 Complete' if phase1_landcover_path else '\u2717 Failed'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_phase2",
   "metadata": {},
   "source": [
    "# Phase 2: Batch Point Generation\n",
    "\n",
    "Generate receiver points using point_generation utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phase2_generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.point_generation import Transmitter, generate_receiver_grid\n\nprint(\"\\nPhase 2: Batch Point Generation\")\nprint(\"=\"*60)\n\n# Create Transmitter object exactly as the real pipeline does\ntransmitter = Transmitter(\n    tx_id=tx_info['tx_id'],\n    lon=tx_info['longitude'],\n    lat=tx_info['latitude'],\n    htg=tx_info['antenna_height_tx'],\n    f=p1812_params['frequency_ghz'],\n    pol=p1812_params['polarization'],\n    p=p1812_params['time_percentage'],\n    hrg=tx_info['antenna_height_rx'],\n)\n\n# Calculate number of azimuths from azimuth_step\nnum_azimuths = int(360 / rx_gen_params['azimuth_step'])\n\nprint(f\"\\nGenerating receiver grid...\")\nprint(f\"  Max distance: {rx_gen_params['max_distance_km']} km\")\nprint(f\"  Distance step: {rx_gen_params['distance_step']} km\")\nprint(f\"  Azimuth step: {rx_gen_params['azimuth_step']}\u00b0\")\nprint(f\"  Number of azimuths: {num_azimuths}\")\n\nstart = time.time()\nreceivers_gdf = generate_receiver_grid(\n    tx=transmitter,\n    max_distance_km=rx_gen_params['max_distance_km'],\n    sampling_resolution_m=rx_gen_params['sampling_resolution'],\n    num_azimuths=num_azimuths,\n    include_tx_point=True,\n)\nelapsed = time.time() - start\n\nprint(f\"\\n\u2713 Generated {len(receivers_gdf)} receiver points in {elapsed:.3f}s\")\nprint(f\"\\nGeoDataFrame structure:\")\nprint(f\"  CRS: {receivers_gdf.crs}\")\nprint(f\"  Columns: {list(receivers_gdf.columns)}\")\nprint(f\"  Distance range: {receivers_gdf['distance_km'].min():.2f}-{receivers_gdf['distance_km'].max():.2f} km\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_phase3",
   "metadata": {},
   "source": [
    "# Phase 3: Batch Data Extraction\n",
    "\n",
    "Extract elevation and land cover at receiver points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phase3_extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.data_extraction import extract_data_for_receivers, RasterPreloader, map_landcover_codes\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\nPhase 3: Batch Data Extraction\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare for real data extraction\n",
    "print(f\"\\nPreparing for batch data extraction...\")\n",
    "print(f\"  Total receiver points: {len(receivers_gdf)}\")\n",
    "\n",
    "# Get land cover mappings from config\n",
    "lcm10_to_ct = CONFIG.get('LCM10_TO_CT', {str(k): v for k, v in enumerate([2]*255)})\n",
    "ct_to_r = CONFIG.get('CT_TO_R', {1: 0, 2: 10, 3: 50, 4: 100, 5: 200})\n",
    "\n",
    "# Try to locate cached landcover data (from Phase 1)\\n\",\n",
    "tx_lat = tx_info['latitude']\n",
    "tx_lon = tx_info['longitude']\n",
    "sh_config = CONFIG.get('SENTINEL_HUB', {})\n",
    "landcover_pattern = f\"lcm10_{tx_lat}_{tx_lon}*.tif\"\n",
    "\n",
    "# Check if landcover exists in cache\n",
    "import glob\n",
    "cached_landcover = glob.glob(str(landcover_dir / landcover_pattern))\n",
    "landcover_path = Path(cached_landcover[0]) if cached_landcover else None\n",
    "\n",
    "if landcover_path and landcover_path.exists():\n",
    "    print(f\"\u2713 Found cached landcover: {landcover_path.name}\")\n",
    "else:\n",
    "    print(f\"\u26a0 No cached landcover found\")\n",
    "    print(f\"  To enable land cover extraction:\")\n",
    "    print(f\"  1. Configure Sentinel Hub credentials in config_sentinel_hub.py\")\n",
    "    print(f\"  2. Run Phase 1 first, or\")\n",
    "    print(f\"  3. Download manually and place in {landcover_dir}\")\n",
    "    landcover_path = None\n",
    "\n",
    "# Prepare DEM path\n",
    "dem_path = srtm_dir / 'SRTM1.vrt'\n",
    "if not dem_path.exists():\n",
    "    # Try to find any HGT files\n",
    "    hgt_files = glob.glob(str(srtm_dir / '*.hgt'))\n",
    "    if hgt_files:\n",
    "        dem_path = Path(hgt_files[0])\n",
    "        print(f\"\u2713 Found SRTM HGT file: {dem_path.name}\")\n",
    "    else:\n",
    "        dem_path = None\n",
    "        print(f\"\u26a0 No DEM data found in {srtm_dir}\")\n",
    "\n",
    "# Prepare zones path\n",
    "zones_path = brzones_dir / 'zones_map_BR.json'\n",
    "if not zones_path.exists():\n",
    "    print(f\"\u26a0 Zones GeoJSON not found at {zones_path}\")\n",
    "    zones_path = None\n",
    "\n",
    "# Perform batch data extraction if we have the data\n",
    "print(f\"\\nBatch data extraction configuration:\")\n",
    "print(f\"  DEM: {dem_path.name if dem_path else 'Not available'}\")\n",
    "print(f\"  Landcover: {landcover_path.name if landcover_path else 'Not available'}\")\n",
    "print(f\"  Zones: {zones_path.name if zones_path else 'Not available'}\")\n",
    "\n",
    "# Always run extraction, even with missing data (graceful fallback)\n",
    "try:\n",
    "    enriched_gdf = extract_data_for_receivers(\n",
    "        receivers_gdf=receivers_gdf.copy(),\n",
    "        dem_path=dem_path or Path('/tmp/dummy.vrt'),\n",
    "        landcover_path=landcover_path or Path('/tmp/dummy.tif'),\n",
    "        zones_path=zones_path or Path('/tmp/dummy.json'),\n",
    "        lcm10_to_ct=lcm10_to_ct,\n",
    "        ct_to_r=ct_to_r,\n",
    "        verbose=True,\n",
    "    )\n",
    "    receivers_gdf = enriched_gdf\n",
    "    extraction_success = True\n",
    "except Exception as e:\n",
    "    # Fallback: manually add default values\\n\",\n",
    "    print(f\"\u26a0 Data extraction failed: {str(e)[:100]}...\")\n",
    "    print(f\"\\nApplying default values as fallback...\")\n",
    "    \n",
    "    # Extract elevation from loaded HGT if available\n",
    "    if dem_band_data is not None:\n",
    "        elevations = []\n",
    "        for idx, row in receivers_gdf.iterrows():\n",
    "            lon, lat = row.geometry.x, row.geometry.y\n",
    "            try:\n",
    "                col, row_idx = rowcol(dem_transform, lon, lat)\n",
    "                if 0 <= col < dem_band_data.shape[1] and 0 <= row_idx < dem_band_data.shape[0]:\n",
    "                    elev = dem_band_data[row_idx, col]\n",
    "                    elevations.append(float(elev) if elev > -32000 else 0.0)\n",
    "                else:\n",
    "                    elevations.append(0.0)\n",
    "            except:\n",
    "                elevations.append(0.0)\n",
    "        receivers_gdf['h'] = elevations\n",
    "    else:\n",
    "        receivers_gdf['h'] = 0.0\n",
    "    \n",
    "    # Default land cover values\n",
    "    receivers_gdf['ct'] = 254  # No-data\n",
    "    receivers_gdf['Ct'] = 2    # Default category: vegetation\n",
    "    receivers_gdf['R'] = 10.0  # Default resistance: 10 ohms\n",
    "    receivers_gdf['zone'] = 4  # Default: Inland\n",
    "    \n",
    "    extraction_success = False\n",
    "    print(f\"\u2713 Applied defaults\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nPhase 3 Complete:\")\n",
    "print(f\"  Status: {'\u2713 Full extraction' if extraction_success else '\u26a0 Fallback defaults'}\")\n",
    "print(f\"  Receiver points: {len(receivers_gdf)}\")\n",
    "print(f\"  Required columns: {all(col in receivers_gdf.columns for col in ['h', 'Ct', 'R', 'zone'])}\")\n",
    "print(f\"\\nData summary:\")\n",
    "print(receivers_gdf[['tx_id', 'rx_id', 'distance_km', 'h', 'Ct', 'R', 'zone']].head(10))\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Elevation: {receivers_gdf['h'].min():.1f} - {receivers_gdf['h'].max():.1f} m\")\n",
    "print(f\"  Categories: {dict(receivers_gdf['Ct'].value_counts().sort_index())}\")\n",
    "print(f\"  Zones: {dict(receivers_gdf['zone'].value_counts().sort_index())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_phase4",
   "metadata": {},
   "source": [
    "# Phase 4: Formatting & Export\n",
    "\n",
    "Format profiles using ProfileFormatter and validate output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phase4_formatting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.formatting import format_and_export_profiles\n\nprint(\"\\nPhase 4: Formatting & Export\")\nprint(\"=\"*60)\n\n# Use the pipeline's format_and_export_profiles function\n# This handles everything: formatting, validation, and CSV export\ndistance_step_km = rx_gen_params['distance_step']  # From config_example.json\n\ncsv_path = profiles_dir / \"demo_profiles.csv\"\nstart = time.time()\ndf_profiles, result_path = format_and_export_profiles(\n    receivers_gdf=receivers_gdf,\n    output_path=csv_path,\n    frequency_ghz=p1812_params['frequency_ghz'],\n    time_percentage=p1812_params['time_percentage'],\n    polarization=p1812_params['polarization'],\n    htg=tx_info['antenna_height_tx'],\n    hrg=tx_info['antenna_height_rx'],\n    distance_step_km=distance_step_km,\n    verbose=True,\n)\nelapsed = time.time() - start\n\nprint(f\"\\nPhase 4 completed in {elapsed:.3f}s\")\nprint(f\"CSV path: {result_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_phase5",
   "metadata": {},
   "source": [
    "# Phase 5: P.1812 Analysis\n",
    "\n",
    "Process profiles through P.1812 propagation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phase5_calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from propagation.propagation_calculator import main as batch_p1812\n\nprint(\"\\nPhase 5: P.1812 Batch Analysis\")\nprint(\"=\"*60)\n\n# Run batch P.1812 processor\noutput_dir = project_root / 'data' / 'output'\noutput_dir.mkdir(parents=True, exist_ok=True)\n\nstart = time.time()\nresult = batch_p1812(\n    profiles_dir=profiles_dir,\n    output_dir=output_dir,\n)\nelapsed = time.time() - start\n\nprint(f\"\\n\u2713 Phase 5 completed in {elapsed:.1f}s\")\nprint(f\"  Results saved to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_utilities",
   "metadata": {},
   "source": [
    "# Utilities: Logging and Validation\n",
    "\n",
    "Demonstrate logging utilities and validation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utilities_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logging import Timer, ProgressTracker, print_header, print_success, print_warning, format_bytes, format_duration\n",
    "from utils.validation import validate_config, validate_dataframe\n",
    "\n",
    "print(\"\\nUtilities Demonstration\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Timer context manager\n",
    "print(\"\\nTimer utility:\")\n",
    "with Timer(\"Example operation\"):\n",
    "    time.sleep(0.1)\n",
    "    print(\"  Doing work...\")\n",
    "\n",
    "# Progress tracker\n",
    "print(\"\\nProgress tracker:\")\n",
    "tracker = ProgressTracker(total=3, name=\"Processing\")\n",
    "tracker.start()  # Must call start() before update()\n",
    "for i in range(3):\n",
    "    time.sleep(0.1)\n",
    "    tracker.update(force=(i==2))  # Force final update\n",
    "    print(f\"  Step {i+1}: {(tracker.current/tracker.total)*100:.1f}% complete\")\n",
    "tracker.finish()\n",
    "\n",
    "# Formatting utilities\n",
    "print(\"\\nFormatting utilities:\")\n",
    "try:\n",
    "    from utils.logging import format_bytes, format_duration\n",
    "    print(f\"  Bytes: {format_bytes(1024*1024)} = 1 MB\")\n",
    "    print(f\"  Duration: {format_duration(3661)} = 1 hour, 1 minute, 1 second\")\n",
    "except ImportError:\n",
    "    print(f\"  format_bytes(1048576) \u2192 1.0 MB\")\n",
    "    print(f\"  format_duration(3661) \u2192 1 hour, 1 minute, 1 second\")\n",
    "\n",
    "# Validation\n",
    "print(\"\\nValidation:\")\n",
    "print(\"  CONFIG validation: \", end=\"\")\n",
    "try:\n",
    "    validate_config(CONFIG)\n",
    "    print(\"\u2713 Valid\")\n",
    "except Exception as e:\n",
    "    print(f\"\u2717 Invalid: {str(e)[:50]}\")\n",
    "\n",
    "print(f\"\\nGeoDataFrame validation: \", end=\"\")\n",
    "try:\n",
    "    validate_dataframe(receivers_gdf, required_cols=['geometry'])\n",
    "    print(f\"\u2713 Valid ({len(receivers_gdf)} rows)\")\n",
    "except Exception as e:\n",
    "    print(f\"\u2717 Invalid: {e}\")\n",
    "\n",
    "print(\"\\n\u2713 All utilities demonstrated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "# Complete Pipeline Summary\n",
    "\n",
    "## Phases Completed\n",
    "1. **Phase 0**: Configuration management with validation\n",
    "2. **Phase 1**: Sentinel Hub data preparation\n",
    "3. **Phase 2**: Receiver point generation (point_generation module)\n",
    "4. **Phase 3**: Data extraction and validation\n",
    "5. **Phase 4**: Profile formatting using ProfileFormatter\n",
    "6. **Phase 5**: P.1812 propagation calculations\n",
    "\n",
    "## Key Modules Demonstrated\n",
    "\n",
    "### Pipeline Modules\n",
    "- **pipeline.config**: ConfigManager, configuration extraction helpers\n",
    "- **pipeline.point_generation**: Transmitter, receiver grid generation\n",
    "- **pipeline.formatting**: ProfileFormatter, CSV validation\n",
    "- **pipeline.data_extraction**: RasterPreloader, zone extraction\n",
    "- **pipeline.orchestration**: PipelineOrchestrator (multi-phase execution)\n",
    "\n",
    "### Propagation Modules\n",
    "- **propagation.profile_extraction**: SRTM utilities, Sentinel Hub helpers\n",
    "- **propagation.profile_parser**: Profile loading and parameter parsing\n",
    "- **propagation.propagation_calculator**: Batch P.1812 processing\n",
    "\n",
    "### Utility Modules\n",
    "- **utils.logging**: Timer, ProgressTracker, formatting utilities\n",
    "- **utils.validation**: Configuration, data, and output validation\n",
    "\n",
    "## Performance Notes\n",
    "- Phase 0-1: ~30-60 seconds\n",
    "- Phase 2-3: ~5-10 seconds\n",
    "- Phase 4: ~2-3 seconds\n",
    "- Phase 5: ~30-60 seconds\n",
    "- **Total**: ~2-3 minutes\n",
    "\n",
    "## Next Steps\n",
    "1. Configure Sentinel Hub credentials\n",
    "2. Modify config_example.json for your location\n",
    "3. Use PipelineOrchestrator for automated multi-phase execution\n",
    "4. Visualize results using output CSV and GeoJSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_visualization",
   "metadata": {},
   "source": [
    "# Phase 6: Results Visualization\n",
    "\n",
    "Visualize pipeline results using interactive Plotly charts and deck.gl maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable inline Plotly display in Jupyter\nimport plotly.io as pio\npio.renderers.default = 'notebook'\n\nfrom utils.visualization import (\n    create_loss_distribution_chart,\n    create_field_strength_chart,\n    create_loss_vs_distance_scatter,\n    create_azimuth_heatmap,\n    create_receiver_map,\n    create_statistics_summary,\n    print_summary,\n)\n\nprint('\\nPhase 6: Results Visualization')\nprint('='*60)\n\n# Load results\noutput_dir = project_root / 'data' / 'output'\nresults_files = list(output_dir.glob('results_*.csv'))\n\nif results_files:\n    latest_results = sorted(results_files, key=lambda p: p.stat().st_mtime)[-1]\n    print(f'\\nLoading results from: {latest_results.name}')\n    \n    results_df = pd.read_csv(latest_results)\n    print(f'\u2713 Loaded {len(results_df)} profile results')\n    \n    # Generate statistics\n    summary = create_statistics_summary(results_df)\n    print_summary(summary)\n    \n    # Create visualizations\n    print('\\nGenerating interactive visualizations...')\n    \n    # Chart 1: Lb distribution\n    print('\\n1. Lb (Basic Transmission Loss) Distribution')\n    fig_lb = create_loss_distribution_chart(results_df)\n    if fig_lb:\n        fig_lb.show()\n    \n    # Chart 2: Ep distribution\n    print('\\n2. Ep (Electric Field Strength) Distribution')\n    fig_ep = create_field_strength_chart(results_df)\n    if fig_ep:\n        fig_ep.show()\n    \n    # Chart 3: Lb vs Distance scatter\n    print('\\n3. Lb vs Distance Scatter Plot (colored by azimuth)')\n    fig_scatter = create_loss_vs_distance_scatter(results_df)\n    if fig_scatter:\n        fig_scatter.show()\n    \n    # Chart 4: Azimuth heatmap\n    print('\\n4. Azimuth-Distance Heatmap')\n    fig_heatmap = create_azimuth_heatmap(results_df)\n    if fig_heatmap:\n        fig_heatmap.show()\n    \n    # Map: Receiver locations with results\n    print('\\n5. Interactive Map (deck.gl) - Receiver Points Colored by Loss')\n    try:\n        from pipeline.config import ConfigManager, get_transmitter_info, get_receiver_generation_params\n        from pipeline.point_generation import Transmitter, generate_receiver_grid\n        \n        config_path = project_root / 'config_example.json'\n        config_mgr = ConfigManager.from_file(config_path)\n        CONFIG = config_mgr.config\n        \n        tx_info = get_transmitter_info(CONFIG)\n        rx_gen_params = get_receiver_generation_params(CONFIG)\n        \n        tx = Transmitter(\n            tx_id=tx_info['tx_id'],\n            lon=tx_info['longitude'],\n            lat=tx_info['latitude'],\n            htg=tx_info['antenna_height_tx'],\n            f=CONFIG['P1812']['frequency_ghz'],\n            pol=CONFIG['P1812']['polarization'],\n            p=CONFIG['P1812']['time_percentage'],\n            hrg=tx_info['antenna_height_rx'],\n        )\n        \n        receivers_gdf = generate_receiver_grid(\n            tx=tx,\n            max_distance_km=rx_gen_params['max_distance_km'],\n            sampling_resolution_m=rx_gen_params['sampling_resolution'],\n            num_azimuths=int(360 / rx_gen_params['azimuth_step']),\n            include_tx_point=True,\n        )\n        \n        output_map_path = project_root / 'data' / 'output' / 'receiver_map.html'\n        deck_map, map_html_path = create_receiver_map(receivers_gdf, results_df, output_path=output_map_path)\n        if deck_map:\n            print(f'Map saved to: {map_html_path}')\n        \n    except Exception as e:\n        print(f'Map error: {str(e)[:100]}')\n    \n    print('\\nVisualization complete')\nelse:\n    print('\\nNo results found. Run Phase 5 first.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_summary_final",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "## Phases Executed\n",
    "1. **Phase 0**: Configuration management with validation\n",
    "2. **Phase 1**: Sentinel Hub data preparation (optional)\n",
    "3. **Phase 2**: Receiver point generation\n",
    "4. **Phase 3**: Data extraction (elevation, landcover, zones)\n",
    "5. **Phase 4**: Profile formatting and CSV export\n",
    "6. **Phase 5**: P.1812 batch processing and results CSV\n",
    "7. **Phase 6**: Results visualization with Plotly and deck.gl\n",
    "\n",
    "## Key Outputs\n",
    "- **Profiles CSV**: `data/profiles/profiles_TX_*.csv` (1,512 profiles with distance arrays)\n",
    "- **Results CSV**: `data/output/results_TX_*.csv` (Lb and Ep for each profile)\n",
    "- **Visualizations**: Interactive charts and maps showing loss/field strength distribution\n",
    "\n",
    "## Next Steps\n",
    "1. Modify `config_example.json` for different locations\n",
    "2. Run the full pipeline for your specific transmitter location\n",
    "3. Analyze results using the provided visualizations\n",
    "4. Export results for further analysis or reporting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (.venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}